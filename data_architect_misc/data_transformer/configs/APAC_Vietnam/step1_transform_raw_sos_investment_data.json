[
  {
    "__comment__": "(Required) Input folder and file name or file name pattern such as 'VTN_N_ALL_INV*.xlsx' (to process multiple files using the same configuration).",
    "__comment__": "Input folder and file name or file name pattern such as 'VTNS_N_ALL_INV*.xlsx' (to process multiple files using the same configuration).",
    "__comment__": "You can skip the two config parameters below related to input folder and file if you run the program like as follow:",
    "__comment__": "E.g., >> python transform.py -c configs/common_qa_config.json -i ./path/to/input/file/input_data_file.xlsx",
    "input_folder_path": "./input/APAC_Vietnam/",
    "input_file_name_or_pattern": "VTN_N_ALL_SOS_KTM_20200301_20200531_20200619_JC.xlsx",

    "__comment_for_rows_per_read__": "(Optional) The number of rows to read and transform per each iteration. If the file has too many rows and if you have limited RAM on your machine, you can enter a reasonable integer value below and the data reader module will only process that many rows at a time (thereby, preventing the out-of-memory errors). Default rows that will be processed per iteration is shown below and even if you don't define this key, the default value below will be used by the program.",
    "rows_per_read": 200000,

    "__comment__": "(Optional) Enter the sheet name of the input Excel file to read data from. Default is the first sheet.",
    "input_sheet_name": "Spots",

    "__comment__": "(Optional) Boolean flag telling if we should write data to a destination place. Default is always True.",
    "write_output": true,

    "__comment__": "(Optional) Relative path of output folder if the data is going to be written to a file. Default is going to be the current working directory of transform.py",
    "__comment__": "Default is going to be the current working directory of transform.py",
    "output_folder_path": "./output/APAC_Vietnam/",

    "__comment__": "(Optional) Prefix for the output file name.",
    "output_file_name_prefix": "transformed_Vietnam_SOS_Spots_Media_20200301_20200531_",

    "__comment__": "(Required if there's header row in your data) Enter the row index (>= 0) to extract column headers from. E.g., if column header row is the first row, enter 0 below.",
    "__comment__": "If this value is NOT provided, the program will assume there is no header row in the input file.",
    "header": 1,

    "__comment__": "(Optional) Specify the row index (>= 0) where the data, *not including the column headers*, begins.",
    "__comment__": "Default is 1 (the second row) because that's where the data usually begins in files (the first row is almost always the column headers).",
    "skiprows": 2,

    "__comment__": "(Optional) Number of rows (>=1) to drop/ignore from the bottom of the data file.",
    "__comment__": "Default is 0, meaning ever row of data will be read, including the last line in the file.",
    "__comment__": "Also, make to define the rows_per_read value such that the rows at the bottom to drop (skipfooter value below) are NOT read in two different iterations/chunks.",
    "__comment__": " If that happens, then the skipfooter will not correctly drop the right number of rows at the bottom.",
    "skipfooter": 0,

    "__comment__": "(Optional) Path+name of that has **CUSTOM** functions for data transformation, which will be imported and used in the transform process.",
    "custom_transform_functions_file": "./transform_functions/apac_vietnam_transform_functions.py",

    "__comment__": "(Required) List of the functions and their parameters.",
    "__comment__": "These functions must be defined either in transform_functions.py or individual task's transform file such as ./transform_function/aed_gcc_transform_functions.py",
    "functions_to_apply": [
      {
        "__function_comment__": "Excel file has empty columns. We need to drop them first",
        "function_name": "drop_unnamed_columns"
      },
      {
        "__function_comment__": "By the time we run this function, there should be only 9 columns total remaining in the raw data frame.",
        "function_name": "assert_number_of_columns_equals",
        "function_args": [9]
      },
      {
        "__function_comment__": "Delete row with value 'Total' from Date column.",
        "function_name": "drop_rows_with_matching_string_values",
        "function_args": [["Date"],[["Total"]]]
      },
      {
        "__function_comment__": "Add PROCESSED_DATE that holds the current date value.",
        "function_name": "add_PROCESSED_DATE_column_with_current_date"
      },
      {
        "__function_comment__": "Create HARMONIZED_YEAR column from existing date column name.",
        "function_name": "add_HARMONIZED_YEAR_column_using_existing_date_column_values",
        "function_args": ["Date"]
      },
      {
        "__function_comment__": "Create HARMONIZED_MONTH column from existing date column name.",
        "function_name": "add_HARMONIZED_MONTH_column_using_existing_date_column_values",
        "function_args": ["Date"]
      },
      {
        "__function_comment__": "Add DATE column based on the values in ***YEAR and MONTH columns created in previous steps***.",
        "function_name": "add_HARMONIZED_DATE_column_using_existing_YEAR_and_MONTH_columns_with_integer_values"
      },
      {
        "__function_comment__": "Add HARMONIZED_REGION as a new column with 'Africa-Eurasia' as value.",
        "function_name": "add_HARMONIZED_REGION_column",
        "function_args": ["Asia Pacific"]
      },
      {
        "__function_comment__": "Create HARMONIZED_COUNTRY column (with standardized country names in comp_harm_constants.py) from raw country name column.",
        "function_name": "add_HARMONIZED_COUNTRY_column",
        "function_args": ["Vietnam"]
      },
      {
        "__function_comment__": "Create HARMONIZED_ADVERTISER column (with standardized advertiser names in comp_harm_constants.py) from existing raw advertiser name column.",
        "function_name": "add_HARMONIZED_ADVERTISER_column_using_existing_advertiser_column",
        "function_args": ["Advertiser"]
      },
      {
        "__function_comment__": "Add HARMONIZED_SUBMEDIA as a new column with '' as value.",
        "function_name": "add_RAW_SUBBRAND_column",
        "function_args": [""]
      },
      {
        "__function_comment__": "Create RAW_PRODUCT_NAME column from existing product name column.",
        "function_name": "add_RAW_PRODUCT_NAME_column_by_renaming_existing_column",
        "function_args": ["Model"]
      },
      {
        "__function_comment__": "Create RAW_BRAND column from existing brand column name.",
        "function_name": "add_RAW_BRAND_column_by_renaming_existing_column",
        "function_args": ["Brand"]
      },
      {
        "__function_comment__": "Create HARMONIZED_GROSS_SPEND column (with values rounded to 2-decimal places) from raw gross spend column.",
        "function_name": "add_HARMONIZED_GROSS_SPEND_column",
        "function_args": ["Cost in VND"]
      },
      {
        "__function_comment__": "Add CURRENCY as a new column with 'UAH' as value.",
        "function_name": "add_HARMONIZED_CURRENCY_column",
        "function_args": ["VND"]
      },
      {
        "__function_comment__": "Create HARMONIZED_CATEGORY column (with standardized category names in comp_harm_constants.py) from raw category name column.",
        "function_name": "add_HARMONIZED_CATEGORY_column_using_existing_category_column",
        "function_args": ["Product"]
      },
      {
        "__function_comment__": "Create HARMONIZED_MEDIA_TYPE column (with standardized Media Type names in comp_harm_constants.py) from raw media type column.",
        "function_name": "add_HARMONIZED_MEDIA_TYPE_column",
        "function_args": ["TV"]
      }
    ]
  },

  {
    "__comment__": "(Required) Input folder and file name or file name pattern such as 'VTN_N_ALL_INV*.xlsx' (to process multiple files using the same configuration).",
    "__comment__": "Input folder and file name or file name pattern such as 'VTNS_N_ALL_INV*.xlsx' (to process multiple files using the same configuration).",
    "__comment__": "You can skip the two config parameters below related to input folder and file if you run the program like as follow:",
    "__comment__": "E.g., >> python transform.py -c configs/common_qa_config.json -i ./path/to/input/file/input_data_file.xlsx",
    "input_folder_path": "./input/APAC_Vietnam/",
    "input_file_name_or_pattern": "VTN_N_ALL_SOS_KTM_20200301_20200531_20200619_JC.xlsx",

    "__comment__": "(Optional) Enter the sheet name of the input Excel file to read data from. Default is the first sheet.",
    "input_sheet_name": "Press",

    "__comment__": "(Optional) Boolean flag telling if we should write data to a destination place. Default is always True.",
    "write_output": true,

    "__comment__": "(Optional) Relative path of output folder if the data is going to be written to a file. Default is going to be the current working directory of transform.py",
    "__comment__": "Default is going to be the current working directory of transform.py",
    "output_folder_path": "./output/APAC_Vietnam/",

    "__comment__": "(Optional) Prefix for the output file name.",
    "output_file_name_prefix": "transformed_Vietnam_SOS_Press_Media_20200301_20200531_",

    "__comment__": "(Required if there's header row in your data) Enter the row index (>= 0) to extract column headers from. E.g., if column header row is the first row, enter 0 below.",
    "__comment__": "If this value is NOT provided, the program will assume there is no header row in the input file.",
    "header": 1,

    "__comment__": "(Optional) Specify the row index (>= 0) where the data, *not including the column headers*, begins.",
    "__comment__": "Default is 1 (the second row) because that's where the data usually begins in files (the first row is almost always the column headers).",
    "skiprows": 2,

    "__comment__": "(Optional) Number of rows (>=1) to drop/ignore from the bottom of the data file.",
    "__comment__": "Default is 0, meaning ever row of data will be read, including the last line in the file.",
    "__comment__": "Also, make to define the rows_per_read value such that the rows at the bottom to drop (skipfooter value below) are NOT read in two different iterations/chunks.",
    "__comment__": " If that happens, then the skipfooter will not correctly drop the right number of rows at the bottom.",
    "skipfooter": 0,

    "__comment__": "(Optional) Path+name of that has **CUSTOM** functions for data transformation, which will be imported and used in the transform process.",
    "custom_transform_functions_file": "./transform_functions/apac_vietnam_transform_functions.py",

    "__comment__": "(Required) List of the functions and their parameters.",
    "__comment__": "These functions must be defined either in transform_functions.py or individual task's transform file such as ./transform_function/aed_gcc_transform_functions.py",
    "functions_to_apply": [
      {
        "__function_comment__": "Excel file has empty columns. We need to drop them first",
        "function_name": "drop_unnamed_columns"
      },
      {
        "__function_comment__": "By the time we run this function, there should be only 10 columns total remaining in the raw data frame.",
        "function_name": "assert_number_of_columns_equals",
        "function_args": [10]
      },
      {
        "__function_comment__": "Add PROCESSED_DATE that holds the current date value.",
        "function_name": "add_PROCESSED_DATE_column_with_current_date"
      },
      {
        "__function_comment__": "Create HARMONIZED_GROSS_SPEND column (with values rounded to 2-decimal places) from raw gross spend column.",
        "function_name": "add_HARMONIZED_GROSS_SPEND_column",
        "function_args": ["Cost in VND"]
      },
      {
        "__function_comment__": "Create RAW_PRODUCT_NAME column from existing product name column.",
        "function_name": "add_RAW_PRODUCT_NAME_column_by_renaming_existing_column",
        "function_args": ["Model"]
      },
      {
        "__function_comment__": "Create RAW_BRAND column from existing brand column name.",
        "function_name": "add_RAW_BRAND_column_by_renaming_existing_column",
        "function_args": ["Brand"]
      },
      {
        "__function_comment__": "Create HARMONIZED_MEDIA_TYPE column (with standardized Media Type names in comp_harm_constants.py) from raw media type column.",
        "function_name": "add_HARMONIZED_MEDIA_TYPE_column",
        "function_args": ["Press"]
      }
    ]
  },

    {
    "__comment__": "(Required) Input folder and file name or file name pattern such as 'VTN_N_ALL_INV*.xlsx' (to process multiple files using the same configuration).",
    "__comment__": "Input folder and file name or file name pattern such as 'VTNS_N_ALL_INV*.xlsx' (to process multiple files using the same configuration).",
    "__comment__": "You can skip the two config parameters below related to input folder and file if you run the program like as follow:",
    "__comment__": "E.g., >> python transform.py -c configs/common_qa_config.json -i ./path/to/input/file/input_data_file.xlsx",
    "input_folder_path": "./input/APAC_Vietnam/",
    "input_file_name_or_pattern": "VTN_N_ALL_SOS_KTM_20200301_20200531_20200619_JC.xlsx",

    "__comment__": "(Optional) Enter the sheet name of the input Excel file to read data from. Default is the first sheet.",
    "input_sheet_name": "Radio",

    "__comment__": "(Optional) Boolean flag telling if we should write data to a destination place. Default is always True.",
    "write_output": true,

    "__comment__": "(Optional) Relative path of output folder if the data is going to be written to a file. Default is going to be the current working directory of transform.py",
    "__comment__": "Default is going to be the current working directory of transform.py",
    "output_folder_path": "./output/APAC_Vietnam/",

    "__comment__": "(Optional) Prefix for the output file name.",
    "output_file_name_prefix": "transformed_Vietnam_SOS_Radio_Media_20200301_20200531_",

    "__comment__": "(Required if there's header row in your data) Enter the row index (>= 0) to extract column headers from. E.g., if column header row is the first row, enter 0 below.",
    "__comment__": "If this value is NOT provided, the program will assume there is no header row in the input file.",
    "header": 1,

    "__comment__": "(Optional) Specify the row index (>= 0) where the data, *not including the column headers*, begins.",
    "__comment__": "Default is 1 (the second row) because that's where the data usually begins in files (the first row is almost always the column headers).",
    "skiprows": 2,

    "__comment__": "(Optional) Number of rows (>=1) to drop/ignore from the bottom of the data file.",
    "__comment__": "Default is 0, meaning ever row of data will be read, including the last line in the file.",
    "__comment__": "Also, make to define the rows_per_read value such that the rows at the bottom to drop (skipfooter value below) are NOT read in two different iterations/chunks.",
    "__comment__": " If that happens, then the skipfooter will not correctly drop the right number of rows at the bottom.",
    "skipfooter": 0,

    "__comment__": "(Optional) Path+name of that has **CUSTOM** functions for data transformation, which will be imported and used in the transform process.",
    "custom_transform_functions_file": "./transform_functions/apac_vietnam_transform_functions.py",

    "__comment__": "(Required) List of the functions and their parameters.",
    "__comment__": "These functions must be defined either in transform_functions.py or individual task's transform file such as ./transform_function/aed_gcc_transform_functions.py",
    "functions_to_apply": [
      {
        "__function_comment__": "Excel file has empty columns. We need to drop them first",
        "function_name": "drop_unnamed_columns"
      },
      {
        "__function_comment__": "By the time we run this function, there should be only 9 columns total remaining in the raw data frame.",
        "function_name": "assert_number_of_columns_equals",
        "function_args": [9]
      },
      {
        "__function_comment__": "Add PROCESSED_DATE that holds the current date value.",
        "function_name": "add_PROCESSED_DATE_column_with_current_date"
      },
      {
        "__function_comment__": "Create HARMONIZED_GROSS_SPEND column (with values rounded to 2-decimal places) from raw gross spend column.",
        "function_name": "add_HARMONIZED_GROSS_SPEND_column",
        "function_args": ["Cost in VND"]
      },
      {
        "__function_comment__": "Create RAW_PRODUCT_NAME column from existing product name column.",
        "function_name": "add_RAW_PRODUCT_NAME_column_by_renaming_existing_column",
        "function_args": ["Model"]
      },
      {
        "__function_comment__": "Create RAW_BRAND column from existing brand column name.",
        "function_name": "add_RAW_BRAND_column_by_renaming_existing_column",
        "function_args": ["Brand"]
      },
      {
        "__function_comment__": "Create HARMONIZED_MEDIA_TYPE column (with standardized Media Type names in comp_harm_constants.py) from raw media type column.",
        "function_name": "add_HARMONIZED_MEDIA_TYPE_column",
        "function_args": ["Radio"]
      }
    ]
  }
]