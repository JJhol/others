[
  {
    "__instruction__": "Update values for the keys labeled as 'Required' below. Optional parameters can be left empty.",
    "__instruction__": "Exclusive means only one of the ensuing options must be used.",

    "__comment__": "(Required) Input folder and file name or file name pattern such as 'SWI_N_ALL_INV*.xlsx' (to process multiple files using the same configuration).",
    "input_folder_path": "./input/switzerland/",
    "input_file_name_or_pattern": "SWI_N_ALL_INV_MFO_20191101_20191130_20200117_MC.xlsx",

    "__comment__": "(Required) Output folder path is required.",
    "output_folder_path": "./output/switzerland/",

    "__comment__": "(Optional) Prefix for the output file name.",
    "output_file_name_prefix": "transformed_switzerland_",

    "__comment__": "(Optional Country-specific file (path+name) that has data transforming functions, which will be imported and used in the transform process.",
    "transform_functions_file": "./transform_functions/switzerland_transform_functions.py",

    "__comment__": "(Required if there's header row in your data) Enter the row index (>= 0) to extract column headers from. E.g., if column header row is the first row, enter 0 below.",
    "__comment__": "If this value is NOT provided, the program will assume there is no header row in the input file.",
    "header": 7,

    "__comment__": "(Optional) Specify the row index (>= 0) where the data, *not including the column headers*, begins.",
    "__comment__": "Default is 1 (the second row) because that's where the data usually begins in files (the first row is almost always the column headers).",
    "skiprows": 8,

    "__comment__": "(Optional) Specify the index (>=0) of rows we should ignore from the bottom of the data file.",
    "__comment__": "Default is 0, meaning there's no rows at the end to skip.",
    "skipfooter": 5,

    "__comment__": "(Required) List of the functions and their parameters in a list like [[\"drop_columns\",[0,2]], ....]",
    "__comment__": "These functions must be defined either in transform_functions.py or individual countries transform file such as switzerland_transform_functions.py",
    "__comment__": "If these functions aren't provided, error would be raised because why even bother running this program if there's nothing to transform/apply, right?",
    "functions_to_apply": [
      {
        "__function_comment__": "Every month, we must adjust the following column indexes in this function because the raw files have different number of columns each month.",
        "transform_function_name": "drop_columns_by_index",
        "transform_function_args": [[10, 11, 12, 13, 14, 15, 16, 17, 21]]
      },
      {
        "transform_function_name": "drop_columns_by_name",
        "transform_function_args": [["Werbungtreibender", "Verlag/Vermarkter", "Sprachgebiet"]]
      },
      {
        "transform_function_name": "rename_columns",
        "transform_function_args": [{
            "Branche": "Sector",
            "Produktgruppe": "Subsector",
            "Produktsegment": "Category",
            "Firma": "Advertiser",
            "Marke": "Brand",
            "Produkt": "Product",
            "Mediengruppe": "Media"
          }]
      },
      {
        "__function_comment__": "When we run this function, there are only 13 columns total left in the raw data frame.",
        "assert_function_name": "assert_number_of_columns_equals",
        "assert_function_args": [[10]]
      }
    ],


    "__comment__": "(Optional) Enter sheet name to process. Default is the first sheet in the Excel file.",
    "sheet_name_of_excel_file": "Gaba Report - Gaba Report",

    "__comment__": "(Optional) CSV encoding and delimiters. If empty, the program uses Pandas defaults (UTF-8 and comma).",
    "input_file_encoding": "",
    "input_file_delimiter": "",
    "output_file_encoding": "",
    "output_file_delimiter": "",

    "__comment__": "(Optional) For CSV files, Maximum number of rows to read, process and output in each program iteration (to not overload computer memory).",
    "__comment__": "If below field is deleted, we use 1,500,000 rows as default value, which is defined in transform_utils.py.",
    "rows_per_chunk_for_csv": 1500000,

    "functions_to_apply_to_data_frame": {
      "maybe we don't need this": "#maybe we don't need this"
    },

    "functions_to_apply_to_columns": {
      "column1": ["Like convert to float"],
      "column2": []
    },

    "functions_to_apply_to_rows": ["Like if column 1 is null, ignore row"],
    "functions_to_apply_to_the_whole_dataframe": [],

    "new_columns_to_add": [{"new_column": ["rules_used_to_populate_this_column"]}]
  }
]
